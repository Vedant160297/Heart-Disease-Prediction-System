{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created/Modified files during execution:\n",
    "#    1. cnn_model.pt (PyTorch CNN weights)\n",
    "#    2. xgboost_model.json (Trained XGBoost model)\n",
    "#    3. combined_embeddings.csv (Optional CSV storing extracted embeddings)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "###############################################################################\n",
    "# 1. DATA LOADING AND PREPROCESSING\n",
    "###############################################################################\n",
    "\n",
    "class HeartImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset to load (image, label) pairs.\n",
    "    Expects:\n",
    "        - image_paths: List of filepaths to images.\n",
    "        - labels: Numpy array or list of labels (0 or 1, for example).\n",
    "        - transform: Any torchvision transform to apply.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def load_structured_data(csv_path):\n",
    "    \"\"\"\n",
    "    Loads tabular data (e.g., age, cholesterol, blood pressure, etc.)\n",
    "    The CSV must contain columns like:\n",
    "       'patient_id', 'age', 'bp', 'cholesterol', 'label', ...\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df\n",
    "\n",
    "###############################################################################\n",
    "# 2. DEFINE A SIMPLE CNN FOR IMAGE EMBEDDING\n",
    "###############################################################################\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A small CNN to extract embeddings from heart-related images.\n",
    "    Modify layers for your dataset and problem complexity.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_embedding_features=128):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4,4))  # adjustable\n",
    "        )\n",
    "        # Flatten + final linear layer to produce embeddings\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, num_embedding_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "###############################################################################\n",
    "# 3. TRAIN THE CNN TO EXTRACT IMAGE EMBEDDINGS\n",
    "###############################################################################\n",
    "\n",
    "def train_cnn(cnn_model, dataloader, num_epochs=2, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Trains the CNN on the labeled images to learn relevant features.\n",
    "    In practice, you might:\n",
    "      - Train a classifier head, or\n",
    "      - Use a pre-trained CNN and fine-tune.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    cnn_model = cnn_model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=lr)\n",
    "\n",
    "    cnn_model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            embeddings = cnn_model(images)\n",
    "            # Suppose we treat the final embedding dimension as classes for simplicity;\n",
    "            # in a real scenario, you might have a separate classification head.\n",
    "            # Here, set \"num_embedding_features = number_of_classes\" if you want direct classification.\n",
    "            loss = criterion(embeddings, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Save CNN weights (optional)\n",
    "    torch.save(cnn_model.state_dict(), \"cnn_model.pt\")\n",
    "\n",
    "###############################################################################\n",
    "# 4. EXTRACT EMBEDDINGS FROM IMAGES AND COMBINE WITH TABULAR DATA\n",
    "###############################################################################\n",
    "\n",
    "def extract_embeddings(cnn_model, dataloader):\n",
    "    \"\"\"\n",
    "    Passes images through the trained CNN to get embeddings.\n",
    "    Returns a numpy array of dimension [num_images, embedding_size].\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    cnn_model = cnn_model.to(device)\n",
    "    cnn_model.eval()\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            embeddings = cnn_model(images)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "            all_labels.append(labels.numpy())\n",
    "\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    return all_embeddings, all_labels\n",
    "\n",
    "###############################################################################\n",
    "# 5. TRAIN XGBOOST ON THE COMBINED FEATURES\n",
    "###############################################################################\n",
    "\n",
    "def train_xgboost(tabular_data, image_embeddings, labels):\n",
    "    \"\"\"\n",
    "    Combines tabular features and image embeddings, trains an XGBoost classifier.\n",
    "    Expects:\n",
    "       tabular_data: 2D array or DataFrame of shape [num_samples, num_tabular_features].\n",
    "       image_embeddings: 2D array of shape [num_samples, embedding_size].\n",
    "       labels: 1D array of length num_samples (0 or 1).\n",
    "\n",
    "    Returns the trained XGBoost model.\n",
    "    \"\"\"\n",
    "    # Combine with image embeddings\n",
    "    combined_features = np.hstack([tabular_data, image_embeddings])\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        combined_features, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=10,\n",
    "        eval_metric='logloss',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = xgb_model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Save the trained XGBoost model (optional)\n",
    "    xgb_model.save_model(\"xgboost_model.json\")\n",
    "\n",
    "    return xgb_model\n",
    "\n",
    "###############################################################################\n",
    "# 6. MAIN EXECUTION (DEMO)\n",
    "###############################################################################\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    This main function demonstrates how to:\n",
    "      1) Load tabular data\n",
    "      2) Load images and build a dataset\n",
    "      3) Train CNN and extract embeddings\n",
    "      4) Train an XGBoost classifier on combined data\n",
    "    NOTE: Replace file paths, CSV columns, label definitions, and\n",
    "          hyperparameters as appropriate for your dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------------------\n",
    "    # A. Load your structured data\n",
    "    # ---------------------------\n",
    "    structured_df = load_structured_data(\"kegel_heart_patients.csv\")\n",
    "    # Example assumption of columns: ['patient_id', 'age', 'bp', 'cholesterol', 'label']\n",
    "    # Filter out the columns you want as features (besides 'patient_id' and 'label')\n",
    "    # Make sure your CSV or data source is correct\n",
    "    feature_cols = [\"age\", \"bp\", \"cholesterol\"]\n",
    "    X_tabular = structured_df[feature_cols].values\n",
    "    y = structured_df[\"label\"].values  # 0 or 1 for heart disease presence/absence\n",
    "\n",
    "    # ---------------------------\n",
    "    # B. Prepare image paths\n",
    "    # ---------------------------\n",
    "    # Suppose 'image_path' column in CSV holds the file path for the corresponding patient's heart-related image\n",
    "    image_paths = structured_df[\"image_path\"].values\n",
    "\n",
    "    # ---------------------------\n",
    "    # C. Build PyTorch dataset/dataloader\n",
    "    # ---------------------------\n",
    "    transform = T.Compose([\n",
    "        T.Resize((64, 64)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset = HeartImageDataset(image_paths, y, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "    # ---------------------------\n",
    "    # D. Train your CNN (or load pre-trained)\n",
    "    # ---------------------------\n",
    "    cnn_model = SimpleCNN(num_embedding_features=64)\n",
    "    # For demonstration, train only a few epochs. Adjust as needed.\n",
    "    train_cnn(cnn_model, dataloader, num_epochs=2, lr=1e-3)\n",
    "\n",
    "    # ---------------------------\n",
    "    # E. Extract image embeddings\n",
    "    # ---------------------------\n",
    "    # Use a new dataloader without shuffle for consistent ordering\n",
    "    inference_dataloader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "    image_embeddings, all_labels = extract_embeddings(cnn_model, inference_dataloader)\n",
    "\n",
    "    # ---------------------------\n",
    "    # F. Train XGBoost classifier\n",
    "    # ---------------------------\n",
    "    xgb_model = train_xgboost(X_tabular, image_embeddings, all_labels)\n",
    "\n",
    "    print(\"Multi-modal heart disease detection pipeline complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
